<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Data Competition">
    <meta name="keywords"  content="lambda">
    <meta name="theme-color" content="#000000">
    
    <title>2019-08-15-Data-competition-From-0-to-1-Part-I - lambda 的博客 | Lambda Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Safari Webpage Icon    by-BY -->
    <link rel="apple-touch-icon" href="/img/apple-touch-icon.png">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://lambda-xmu.github.io/2018/08/15/Data-competition-From-0-to-1-Part-I/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <script type="text/x-mathjax-config"> 
   		MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); 
   	</script>
    <script type="text/x-mathjax-config">
    	MathJax.Hub.Config({tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             processEscapes: true
           }
         });
    </script>
    
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
    </script>
    
    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">lambda</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-2015.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/post-bg-2015.jpg')
    }

    
</style>
<header class="intro-header" >
    <div class="header-mask"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#Data Competition" title="Data Competition">Data Competition</a>
                        
                        <a class="tag" href="/tags/#EDA" title="EDA">EDA</a>
                        
                        <a class="tag" href="/tags/#Unbalance" title="Unbalance">Unbalance</a>
                        
                        <a class="tag" href="/tags/#Metrics" title="Metrics">Metrics</a>
                        
                        <a class="tag" href="/tags/#Sampling" title="Sampling">Sampling</a>
                        
                    </div>
                    <h1>2019-08-15-Data-competition-From-0-to-1-Part-I</h1>
                    
                    
                    <h2 class="subheading">Credit Fraud Detector Example</h2>
                    
                    <span class="meta">Posted by lambda on August 15, 2018</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

				<blockquote>
  <p>Concat: <a href="https://github.com/lambda-xmu">github: lambda_xmu</a></p>
</blockquote>

<h2 id="1-data-competition-introduction">1. Data competition Introduction</h2>
<p>A typical data science process might look like this:</p>

<ul>
  <li>Project Scoping / Data Collection</li>
  <li>Exploratory Data Analysis</li>
  <li>Process(Data Cleaning)</li>
  <li>Feature Engineering</li>
  <li>Model Training (including cross-validation to tune hyper-parameters)</li>
  <li>Project Delivery / Insights</li>
</ul>

<p><img src="http://lambda-xmu.github.io/img/data competition.png" alt="" /></p>

<h2 id="2-example-credit-fraud-detector">2. Example: <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit Fraud Detector</a></h2>
<p><strong>Competition Describe</strong></p>
<ul>
  <li>The datasets contains transactions made by credit cards in September 2013 by european cardholders.</li>
  <li>Features V1, V2, … V28 are the principal components obtained with PCA</li>
  <li>Feature <code class="highlighter-rouge">Time</code> contains the seconds elapsed between each transaction and the first transaction in the dataset.</li>
  <li>The feature <code class="highlighter-rouge">Amount</code> is the transaction Amount.</li>
  <li>Feature <code class="highlighter-rouge">Class</code> is the response variable and it takes value 1 in case of fraud and 0 otherwise.</li>
</ul>

<h3 id="edaexploratory-data-analysis">EDA(Exploratory Data Analysis)</h3>
<ul>
  <li>Gathering a basic sense of data</li>
  <li>Example:
    <ul>
      <li>Shape(Traing Size, Test size)</li>
      <li>Label(Binary or Multi or Regression, Distribution)</li>
      <li>Columns(Meaning, Numerical or Time or Category)</li>
      <li><code class="highlighter-rouge">Null</code> Values, how to deal with</li>
      <li>Numerical variable: Distribution</li>
      <li>Outliers</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># import library</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_column'</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">10</span>
<span class="c"># plt.figure(figsize=(14, 10))</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c"># 可以省略 plt.show()</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># simple ead ways</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/creditcard.csv'</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="n">data</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">columns</span>
<span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="nb">sum</span><span class="p">()</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span> <span class="c"># 包含缺失最多的一列有多少</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="nb">any</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="nb">any</span><span class="p">()</span> <span class="c"># 数据中是否有缺失值</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Amount-histogram</span>
<span class="n">Fraud_transacation</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">"Class"</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Normal_transacation</span><span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">"Class"</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">Fraud_transacation</span><span class="o">.</span><span class="n">Amount</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"Fraud Transacation"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">Normal_transacation</span><span class="o">.</span><span class="n">Amount</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"Normal Transaction"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>

<span class="c"># Amount-Time</span>
<span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Time of transaction vs Amount by class'</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Fraud</span><span class="o">.</span><span class="n">Time</span><span class="p">,</span> <span class="n">Fraud</span><span class="o">.</span><span class="n">Amount</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Fraud'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Normal</span><span class="o">.</span><span class="n">Time</span><span class="p">,</span> <span class="n">Normal</span><span class="o">.</span><span class="n">Amount</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Normal'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Time (in Seconds)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Amount'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c"># correlation</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span><span class="n">vmax</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c">## After sampling ?</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="s">'hour'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Time'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="mi">3600</span><span class="p">)</span> <span class="o">%</span> <span class="mi">24</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">values</span><span class="o">=</span><span class="s">'Amount'</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="s">'hour'</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="s">'Class'</span><span class="p">,</span><span class="n">aggfunc</span><span class="o">=</span><span class="s">'count'</span><span class="p">)</span>
<span class="c"># https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot_table.html</span>

<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'hour'</span><span class="p">]</span><span class="o">.</span><span class="nb">min</span><span class="p">(),</span><span class="n">data</span><span class="p">[</span><span class="s">'hour'</span><span class="p">]</span><span class="o">.</span><span class="nb">max</span><span class="p">()</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
<span class="c"># plt.figure(figsize=(15,4))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mf">0.0</span><span class="p">][</span><span class="s">'hour'</span><span class="p">],</span>
             <span class="n">norm_hist</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
             <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span>
             <span class="n">kde</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span>
             <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="o">.</span><span class="mi">5</span><span class="p">},</span>
             <span class="n">label</span><span class="o">=</span><span class="s">'Legit'</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span><span class="o">==</span><span class="mf">1.0</span><span class="p">][</span><span class="s">'hour'</span><span class="p">],</span>
             <span class="n">norm_hist</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
             <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span>
             <span class="n">kde</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
             <span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">'Fraud'</span><span class="p">,</span>
             <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span><span class="o">.</span><span class="mi">5</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># https://github.com/pandas-profiling/pandas-profiling</span>
<span class="kn">import</span> <span class="nn">pandas_profiling</span>

<span class="n">profile</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">profile_report</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"Credit Fraud Detector"</span><span class="p">)</span>
<span class="n">profile</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="n">output_file</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s">"./credit_fraud_detector.html"</span><span class="p">))</span>
</code></pre></div></div>
<p><strong>EDA Conclusion</strong></p>
<blockquote>
  <ul>
    <li>The data set is highly skewed, consisting of 492 frauds in a total of 284,807 observations. This resulted in only 0.172% fraud cases.</li>
    <li>There is no missing value in the dataset.</li>
    <li>The <code class="highlighter-rouge">Time</code> and <code class="highlighter-rouge">Amount</code> features are not transformed data.</li>
  </ul>
</blockquote>

<h4 id="why-taking-log-transformation-of-continuous-variables">Why taking log transformation of continuous variables?</h4>
<p>Amount distribution is “power law”, meaning that the vast majority of amount are small and very few are big.</p>

<script type="math/tex; mode=display">\begin{array}{c}{\log \left(10^{4}\right)=4 * \log (10)} \\ {\log \left(10^{3}\right)=3 * \log (10)} \\ {10^{4}-10^{3}} \\ {4-3}\end{array}</script>

<p>which transforms a huge difference in a smaller one. <strong>Logarithm naturally reduces the dynamic range of a variable so the differences are preserved while the scale is not that dramatically skewed.</strong></p>

<h3 id="outliers-detection">Outliers Detection</h3>
<ul>
  <li><strong>Point anomalies</strong>: A single instance of data is anomalous if it’s too far off from the rest.</li>
  <li><strong>Contextual anomalies</strong>: The abnormality is context specific. This type of anomaly is common in time-series data.</li>
</ul>

<p><img src="http://lambda-xmu.github.io/img/anomaly.png" alt="" /></p>

<script type="math/tex; mode=display">\mathrm{IQR}=Q_{3}-Q_{1}</script>

<script type="math/tex; mode=display">\text{Outliers}: >Q_3+k \cdot IQR</script>

<script type="math/tex; mode=display">% <![CDATA[
\text{Outliers}: <Q_1-k \cdot IQR %]]></script>

<p>The higher $k$ is (ex: 3), the less outliers will detect, and the lower $k$ is (ex: 1.5) the more outliers it will detect.</p>

<p><strong>We want to focus more on “extreme outliers” rather than just outliers.</strong></p>

<h3 id="unbalance">Unbalance</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">count_classes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">],</span> <span class="n">sort</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="n">count_classes</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'bar'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Fraud class histogram"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Class"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Frequency"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="http://lambda-xmu.github.io/img/class_distribution.png" alt="" /></p>

<ul>
  <li>Collect more data</li>
  <li>Using the weights parameters
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s">'balanced'</span><span class="p">)</span>
<span class="c"># How to choose weights?</span>
</code></pre></div>    </div>
  </li>
  <li>Changing the performance metric:
    <ul>
      <li><code class="highlighter-rouge">Precision</code>, <code class="highlighter-rouge">Recall</code></li>
      <li><code class="highlighter-rouge">F1-score</code></li>
      <li><code class="highlighter-rouge">ROC</code> curves</li>
    </ul>
  </li>
  <li>Resampling the dataset
    <ul>
      <li><code class="highlighter-rouge">OVER-sampling</code></li>
      <li><code class="highlighter-rouge">UNDER-sampling</code></li>
      <li><code class="highlighter-rouge">SMOTE</code></li>
    </ul>
  </li>
</ul>

<h3 id="metrics">Metrics</h3>
<p><strong>Confusion Matrix</strong>
<img src="http://lambda-xmu.github.io/img/prediction.png" alt="" /></p>
<ul>
  <li><code class="highlighter-rouge">True Positives</code> : The cases in which we predicted YES and the actual output was also YES.</li>
  <li><code class="highlighter-rouge">True Negatives</code> : The cases in which we predicted NO and the actual output was NO.</li>
  <li><code class="highlighter-rouge">False Positives</code> : The cases in which we predicted YES and the actual output was NO.</li>
  <li><code class="highlighter-rouge">False Negatives</code> : The cases in which we predicted NO and the actual output was YES.
<img src="http://lambda-xmu.github.io/img/Confusion Matrix2.png" alt="" /></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## homework ##</span>
<span class="k">def</span> <span class="nf">find_TP</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># counts the number of true positives (y_true = 1, y_pred = 1)</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">((</span><span class="n">y_true</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">find_FN</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># counts the number of false negatives (y_true = 1, y_pred = 0)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
<span class="k">def</span> <span class="nf">find_FP</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># counts the number of false positives (y_true = 0, y_pred = 1)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
<span class="k">def</span> <span class="nf">find_TN</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># counts the number of true negatives (y_true = 0, y_pred = 0)</span>
    <span class="k">return</span> <span class="c"># your code here</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">find_conf_matrix_values</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># calculate TP, FN, FP, TN</span>
    <span class="n">TP</span> <span class="o">=</span> <span class="n">find_TP</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">FN</span> <span class="o">=</span> <span class="n">find_FN</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">FP</span> <span class="o">=</span> <span class="n">find_FP</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">TN</span> <span class="o">=</span> <span class="n">find_TN</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span>
<span class="k">def</span> <span class="nf">my_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">find_conf_matrix_values</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">TN</span><span class="p">,</span><span class="n">FP</span><span class="p">],[</span><span class="n">FN</span><span class="p">,</span><span class="n">TP</span><span class="p">]])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Accuracy</strong></p>

<script type="math/tex; mode=display">\text{Accuracy}=\frac{\text{True Positives}+\text{True Negatives}}{\text{Total Number of Predictions}}</script>

<ul>
  <li>It works well only if there are equal number of samples belonging to each class.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># homework</span>
<span class="k">def</span> <span class="nf">my_accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># calculates the fraction of samples predicted correctly</span>
    <span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">find_conf_matrix_values</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">accuracy_score</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Precision</strong></p>

<script type="math/tex; mode=display">\text{Precision}=\frac{\text{True Positives}}{\text{True Positives}+\text{False Positives}}</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># homework</span>
<span class="k">def</span> <span class="nf">my_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># calculates the fraction of predicted positives samples that are actually positive</span>
    <span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">find_conf_matrix_values</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span>
<span class="n">precision_score</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Recall</strong></p>

<script type="math/tex; mode=display">\text{Recall}=\frac{\text{True Positives}}{\text{True Positives}+\text{False Negatives}}</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># homework</span>
<span class="k">def</span> <span class="nf">my_recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># calculates the fraction of positive samples predicted correctly</span>
    <span class="n">TP</span><span class="p">,</span><span class="n">FN</span><span class="p">,</span><span class="n">FP</span><span class="p">,</span><span class="n">TN</span> <span class="o">=</span> <span class="n">find_conf_matrix_values</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span>
<span class="n">recall_score</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>F1 Score</strong></p>

<p>The f1 score is the harmonic mean(调和平均) of recall and precision, with a higher score as a better model.</p>

<script type="math/tex; mode=display">F 1=\frac{2}{\frac{1}{\text { precision }}+\frac{1}{\text { recall }}}=\frac{2 * \text { (precision * recall) }}{\text { precision }+\text {recall}}</script>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># homework</span>
<span class="k">def</span> <span class="nf">my_f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="c"># calculates the F1 score</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">my_recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">my_precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="c"># your code here</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="n">f1_score</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>We often assume that we defined a threshold of 0.5 for selecting which samples are predicted as positive. If we change this threshold the performance metrics will change.</strong> It would be nice to be able to evaluate the performance of a model without the need to select an arbitrary threshold. This is precisely what <code class="highlighter-rouge">AUC-ROC</code> is providing.</p>

<p><strong>Area Under Curve (AUC)</strong>–Area Under the curve of the Receiver Operating Characteristic (AUROC)</p>

<p>AUC is used for binary classification problem.</p>

<ul>
  <li>True Positive Rate (Sensitivity) : the proportion of positive data points that are correctly considered as positive, with respect to all positive data points.</li>
</ul>

<script type="math/tex; mode=display">\text{True Positive Rate}=\frac{\text{True Positives}}{\text{True Positives}+\text{False Negatives}}</script>

<ul>
  <li>False Positive Rate (Specificity) : the proportion of negative data points that are mistakenly considered as positive, with respect to all negative data points.</li>
</ul>

<script type="math/tex; mode=display">\text{False Positive Rate}=\frac{\text{False Positives}}{\text{False Positives}+\text{True Negatives}}</script>

<p><code class="highlighter-rouge">FPR</code> and <code class="highlighter-rouge">TPR</code> bot hare computed at threshold values such as $(0.00, 0.02, 0.04, …., 1.00)$ and a graph is drawn. <code class="highlighter-rouge">AUC</code> is the area under the curve of plot <code class="highlighter-rouge">False Positive Rate</code> vs <code class="highlighter-rouge">True Positive Rate</code> at different points in $[0, 1]$. The resulting curve is called ROC curve (Receiver Operating Characteristic curve).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True Positive Rate'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="http://lambda-xmu.github.io/img/auc.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">fast_auc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_prob</span><span class="p">):</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_prob</span><span class="p">)]</span>
    <span class="n">nfalse</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">auc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_true</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">y_i</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">nfalse</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_i</span><span class="p">)</span>
        <span class="n">auc</span> <span class="o">+=</span> <span class="n">y_i</span> <span class="o">*</span> <span class="n">nfalse</span>
    <span class="n">auc</span> <span class="o">/=</span> <span class="p">(</span><span class="n">nfalse</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">nfalse</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">auc</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## test speed</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1000000</span><span class="p">)</span>

<span class="n">fast_auc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="o">%</span><span class="n">timeit</span> <span class="n">fast_auc</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="o">%</span><span class="n">timeit</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<p>You can learn more about <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC on the Wikipedia page</a> and <a href="https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it">What does AUC stand for and what is it?</a>.</p>

<p><strong>Mean Absolute Error(MAE)</strong></p>

<script type="math/tex; mode=display">\text {MAE}=\frac{1}{N} \sum_{j=1}^{N}\left|y_{j}-\hat{y}_{j}\right|</script>

<p><strong>Mean Squared Error(MSE)</strong></p>

<script type="math/tex; mode=display">\text {MSE}=\frac{1}{N} \sum_{j=1}^{N}\left(y_{j}-\hat{y}_{j}\right)^{2}</script>

<p><strong>Log Loss</strong></p>

<p><code class="highlighter-rouge">AUC</code> only takes into account <strong>the order of probabilities</strong> and hence it does not take into account the model’s capability to predict higher probability for samples more likely to be positive.</p>

<script type="math/tex; mode=display">\text {Log Loss}=-\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{M} y_{i j} * \log \left(p(y_{i j})\right)</script>

<ul>
  <li>$y_{ij}$: whether sample $i$ belongs to class $j$ or not</li>
  <li>$p(y_{i j})$: the probability of sample $i$ belonging to class $j$</li>
</ul>

<script type="math/tex; mode=display">\text {Log Loss}=-\frac{1}{N} \sum_{i=1}^{N} y_{i} \cdot \log \left(p\left(y_{i}\right)\right)+\left(1-y_{i}\right) \cdot \log \left(1-p\left(y_{i}\right)\right)</script>

<h3 id="resampling">Resampling</h3>

<p><strong>Under-Sampling</strong>: samples from the majority class
<strong>Over-Sampling</strong>: adding more examples from the minority class</p>

<p><strong>Under-Sampling Drawback</strong>: Removing information that may be valuable. This could lead to underfitting and poor generalization to the test set.</p>

<p>![]avatar(http://lambda-xmu.github.io/img/resampling.png)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">### Create A Small Unbalanced Sample Dataset</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">resample</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">class_sep</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_redundant</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">flip_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'target'</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">'Count (target)'</span><span class="p">)</span>

<span class="c">### Oversample minority class</span>
<span class="n">minority_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">magority_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>

<span class="c"># oversample minority</span>
<span class="n">upsampled_data</span> <span class="o">=</span> <span class="n">resample</span><span class="p">(</span><span class="n">minority_data</span><span class="p">,</span>
                          <span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c"># sample with replacement</span>
                          <span class="n">n_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">magority_data</span><span class="p">),</span> <span class="c"># match number in majority class</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="mi">27</span><span class="p">)</span> <span class="c"># reproducible results</span>

<span class="c"># combine majority and upsampled minority</span>
<span class="n">upsampled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">upsampled_data</span><span class="p">,</span> <span class="n">magority_data</span><span class="p">])</span>

<span class="c"># check new class counts</span>
<span class="n">upsampled</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c">### Undersample majority class</span>
<span class="n">downsampled_data</span> <span class="o">=</span> <span class="n">resample</span><span class="p">(</span><span class="n">magority_data</span><span class="p">,</span>
                            <span class="n">replace</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="c"># sample without replacement</span>
                            <span class="n">n_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">minority_data</span><span class="p">),</span> <span class="c"># match minority n</span>
                            <span class="n">random_state</span> <span class="o">=</span> <span class="mi">27</span><span class="p">)</span> <span class="c"># reproducible results</span>

<span class="c"># combine minority and downsampled majority</span>
<span class="n">downsampled</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">minority_data</span><span class="p">,</span> <span class="n">downsampled_data</span><span class="p">])</span>

<span class="c"># checking counts</span>
<span class="n">downsampled</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>

<p><strong>Imbalanced-Learn</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_2d_space</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">y</span> <span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'Classes'</span><span class="p">):</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'#1F77B4'</span><span class="p">,</span> <span class="s">'#FF7F0E'</span><span class="p">]</span>
    <span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="s">'o'</span><span class="p">,</span> <span class="s">'s'</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,(</span><span class="n">ax1</span><span class="p">,</span><span class="n">ax2</span><span class="p">)</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">colors</span><span class="p">,</span> <span class="n">markers</span><span class="p">):</span>
        <span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span><span class="o">==</span><span class="n">l</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">l</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">m</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">colors</span><span class="p">,</span> <span class="n">markers</span><span class="p">):</span>
        <span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">l</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">l</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">m</span>
        <span class="p">)</span>

    <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'original data'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">imblearn</span>
<span class="c">### Random under-sampling with imbalanced-learn</span>
<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>

<span class="n">ran</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">return_indices</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c">##intialize to return indices of dropped rows</span>
<span class="n">X_rs</span><span class="p">,</span><span class="n">y_rs</span><span class="p">,</span><span class="n">dropped</span> <span class="o">=</span> <span class="n">ran</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"The number of removed indices are "</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">dropped</span><span class="p">))</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_rs</span><span class="p">,</span> <span class="n">y_rs</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="s">'Random under sampling'</span><span class="p">)</span>

<span class="c">### Random over-sampling with imbalanced-learn</span>
<span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>

<span class="n">ran</span><span class="o">=</span><span class="n">RandomOverSampler</span><span class="p">()</span>
<span class="n">X_ran</span><span class="p">,</span><span class="n">y_ran</span><span class="o">=</span> <span class="n">ran</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'The new data contains {} rows '</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_ran</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_ran</span><span class="p">,</span><span class="n">y_ran</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s">'over-sampled'</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Under-sampling: Tomek links</strong></p>

<p><strong>Tomek links</strong> are pairs of very close instances, but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process.</p>

<p><img src="http://lambda-xmu.github.io/img/tomek.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">TomekLinks</span>

<span class="n">tl</span> <span class="o">=</span> <span class="n">TomekLinks</span><span class="p">(</span><span class="n">return_indices</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="s">'majority'</span><span class="p">)</span>
<span class="n">X_tl</span><span class="p">,</span> <span class="n">y_tl</span><span class="p">,</span> <span class="n">id_tl</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c">#print('Removed indexes:', id_tl)</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_tl</span><span class="p">,</span> <span class="n">y_tl</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s">'Tomek links under-sampling'</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>Over-sampling: SMOTE</strong></p>

<p><strong>SMOTE (Synthetic Minority Oversampling TEchnique)</strong> consists of synthesizing elements for the minority class, based on those that already exist. It works randomly picingk a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.</p>

<p><img src="http://lambda-xmu.github.io/img/smote 2.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">ratio</span><span class="o">=</span><span class="s">'minority'</span><span class="p">)</span>
<span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s">'SMOTE over-sampling'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="cross-validation-evaluating-estimator-performance">Cross-validation: evaluating estimator performance</h3>

<p>Trained model would have a perfect score on training data but would fail to predict anything useful on yet-unseen data. This situation is called <code class="highlighter-rouge">overfitting</code>. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set <code class="highlighter-rouge">X_test</code>, <code class="highlighter-rouge">y_test</code>. Here is a flowchart of typical cross validation workflow in model training.</p>

<p><img src="http://lambda-xmu.github.io/img/grid_search_workflow.png" alt="" /></p>

<p><strong><code class="highlighter-rouge">k-folds</code></strong>:</p>
<ul>
  <li>A model is trained using <code class="highlighter-rouge">k-1</code> of the folds as training data;</li>
  <li>the resulting model is validated on the remaining part of the data.</li>
</ul>

<p>The performance measure reported by <code class="highlighter-rouge">k-fold</code> cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data.</p>

<p><img src="http://lambda-xmu.github.io/img/grid_search_cross_validation.png" alt="" /></p>

<h4 id="cross-validation-iterators">Cross validation iterators</h4>
<p><strong>Cross-validation iterators for i.i.d. data</strong>
<strong><code class="highlighter-rouge">K-fold</code></strong></p>

<p><img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0041.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s">"a"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"d"</span><span class="p">]</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<p><strong><code class="highlighter-rouge">Random permutations cross-validation a.k.a. Shuffle &amp; Split</code></strong>
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0061.png" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">ss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>Cross-validation iterators with stratification based on class labels</strong>
Some classification problems can exhibit a large imbalance in the distribution of the target classes.</p>

<p><strong><code class="highlighter-rouge">Stratified k-fold</code></strong>
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0071.png" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<p><strong><code class="highlighter-rouge">Stratified Shuffle Split</code></strong>
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0091.png" alt="" /></p>

<h4 id="cross-validation-iterators-for-grouped-data">Cross-validation iterators for grouped data</h4>
<p>The i.i.d. assumption is broken if the underlying generative process yield groups of dependent samples.</p>

<p><strong><code class="highlighter-rouge">Group k-fold</code></strong>
GroupKFold is a variation of k-fold which ensures that the same group is not represented in both testing and training sets.
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0051.png" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupKFold</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s">"a"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"d"</span><span class="p">,</span> <span class="s">"d"</span><span class="p">,</span> <span class="s">"d"</span><span class="p">]</span>
<span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="n">gkf</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<p><strong><code class="highlighter-rouge">Group Shuffle Split</code></strong>
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0081.png" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupShuffleSplit</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s">"a"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"b"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"c"</span><span class="p">,</span> <span class="s">"a"</span><span class="p">]</span>
<span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">gss</span> <span class="o">=</span> <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<p><strong><code class="highlighter-rouge">Leave P Groups Out</code></strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeavePGroupsOut</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">lpgo</span> <span class="o">=</span> <span class="n">LeavePGroupsOut</span><span class="p">(</span><span class="n">n_groups</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">lpgo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<h4 id="cross-validation-of-time-series-data">Cross validation of time series data</h4>
<p><code class="highlighter-rouge">k-fold</code> 假设数据是 <code class="highlighter-rouge">iid</code> 的，但是时间序列存在相关性，因此不能简单使用 <code class="highlighter-rouge">k-fold</code>。
<img src="http://lambda-xmu.github.io/img/sphx_glr_plot_cv_indices_0101.png" alt="" /></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">TimeSeriesSplit</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%</span><span class="s">s </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="modeling">Modeling</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">data</span><span class="p">[</span><span class="s">'normAmount'</span><span class="p">]</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Amount'</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Amount'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="c"># Whole dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="n">c_param</span><span class="p">,</span> <span class="n">penalty</span> <span class="o">=</span> <span class="s">'l1'</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c"># compare y_test with y_pred</span>
</code></pre></div></div>


                <hr style="visibility: hidden;">

                <ul class="pager">
                    
                    
                    <li class="next">
                        <a href="/2018/08/20/Speed-Up-Python-Code/" data-toggle="tooltip" data-placement="top" title="2019-08-20-Speed-Up-Python-Code">
                        Next<br>
                        <span>2019-08-20-Speed-Up-Python-Code</span>
                        </a>
                    </li>
                    
                </ul>


                <!--Gitalk评论start  -->
                
                <!-- 引入Gitalk评论插件  -->
                <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
                <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
                <div id="gitalk-container"></div>
                <!-- 引入一个生产md5的js，用于对id值进行处理，防止其过长 -->
                <!-- Thank DF:https://github.com/NSDingFan/NSDingFan.github.io/issues/3#issuecomment-407496538 -->
                <script src="/js/md5.min.js"></script>
                <script type="text/javascript">
                    var gitalk = new Gitalk({
                    clientID: 'b20f94fc4df8d27e0ca5',
                    clientSecret: '621774eb54b29c82b5f0f2d97f4b81245c009c4b',
                    repo: 'lambda-xmu.github.io',
                    owner: 'lambda-xmu',
                    admin: ['lambda-xmu'],
                    distractionFreeMode: true,
                    id: md5(location.pathname),
                    });
                    gitalk.render('gitalk-container');
                </script>
                
                <!-- Gitalk end -->

                

            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <hr class="hidden-sm hidden-xs">
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
        				
                            
                				<a href="/tags/#Data Competition" title="Data Competition" rel="2">
                                    Data Competition
                                </a>
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
                            
        				
        			</div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">
                    
                        <li><a href="https://github.com/drop-out">drop-out</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>






<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        // BY Fix:去除标题前的‘#’ issues:<https://github.com/qiubaiying/qiubaiying.github.io/issues/137>
        // anchors.options = {
        //   visible: 'always',
        //   placement: 'right',
        //   icon: '#'
        // };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    <!-- add jianshu add target = "_blank" to <a> by BY -->
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/eureka-42-21">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                    
                    


                    
                    
                    <li>
                        <a target="_blank" href="https://github.com/lambda-xmu">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; lambda 2019
                    <br>
                    Theme on <a href="https://github.com/lambda-xmu/lambda-xmu.github.io.git">GitHub</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=lambda-xmu&repo=lambda-xmu.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->

<script type="text/javascript">
    if(navigator.serviceWorker){
        // For security reasons, a service worker can only control the pages that are in the same directory level or below it. That's why we put sw.js at ROOT level.
        navigator.serviceWorker
            .register('/sw.js')
            .then((registration) => {console.log('Service Worker Registered. ', registration)})
            .catch((error) => {console.log('ServiceWorker registration failed: ', error)})
    }
</script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/ 
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers   
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->

<script>
    // dynamic User by Hux
    var _gaId = 'UA-145892110-1';
    var _gaDomain = 'lambda-xmu.club';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>



<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = 'd4944c30a9161ff9830632d01557244e';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>




<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog (selector) {
        var P = $('div.post-container'),a,n,t,l,i,c;
        a = P.find('h1,h2,h3,h4,h5,h6');
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#"+$(this).prop('id');
            t = $(this).text();
            c = $('<a href="'+i+'" rel="nofollow">'+t+'</a>');
            l = $('<li class="'+n+'_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;    
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function(e){
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>





<!-- Image to hack wechat -->
<img src="/img/apple-touch-icon.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
